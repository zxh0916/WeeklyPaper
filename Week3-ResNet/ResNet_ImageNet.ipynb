{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cc996b-58d3-4de4-bba5-5e68b8795f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0e6b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 2) (10357, 121)\n"
     ]
    }
   ],
   "source": [
    "path = '../data/dog-breed-identification/'\n",
    "train_csv = pd.read_csv(path + 'labels.csv')\n",
    "label_list = sorted(train_csv['breed'].unique().tolist())\n",
    "test_csv = pd.read_csv(path + 'sample_submission.csv')\n",
    "print(train_csv.shape, test_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74189929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# for i in range(len(train_csv['id'])):\n",
    "#     image = (transforms.ToTensor()(Image.open(path + 'train/' + train_csv['id'][i] + '.jpg'))).to(torch.float32).flatten(1, 2)\n",
    "#     images.append(image)\n",
    "# flattened_image = torch.cat(images, dim=1)\n",
    "# print(flattened_image.shape)                                    # torch.Size([3, 1882650608])\n",
    "# print(flattened_image.mean(dim=1), flattened_image.std(dim=1))  # tensor([0.4736, 0.4504, 0.3909]) tensor([0.2655, 0.2607, 0.2650])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97cdc339-804e-44ec-9f22-d8405c6baa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.trans = transforms.Compose([transforms.RandomCrop(224),\n",
    "                                         transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                         transforms.ColorJitter(brightness=0.2,\n",
    "                                                                contrast=0.2,\n",
    "                                                                saturation=0.2,\n",
    "                                                                hue=0.2),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.4736, 0.4504, 0.3909],\n",
    "                                                              std=[0.2655, 0.2607, 0.2650],\n",
    "                                                              inplace=True)])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset[index]\n",
    "        resize = transforms.Resize(random.randint(256, 480))\n",
    "        return self.trans(resize(image)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adcb6799-b5d3-442c-ab71-15f9b3af9d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.trans = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.TenCrop(224),\n",
    "                                         transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                                         transforms.Normalize(mean=[0.4736, 0.4504, 0.3909],\n",
    "                                                              std=[0.2655, 0.2607, 0.2650],\n",
    "                                                              inplace=True)])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset[index]\n",
    "        return self.trans(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337ec6b3-aaa3-474a-9ef5-5f6c3cc085c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ValidDataset(data.Dataset):\n",
    "#     def __init__(self, dataset):\n",
    "#         super().__init__()\n",
    "#         self.dataset = dataset\n",
    "#         self.trans = transforms.Compose([\n",
    "#                                          # transforms.Resize(256),\n",
    "#                                          # transforms.CenterCrop(224),\n",
    "#                                          transforms.ToTensor(),\n",
    "#                                          transforms.Normalize(mean=[0.4736, 0.4504, 0.3909],\n",
    "#                                                               std=[0.2655, 0.2607, 0.2650],\n",
    "#                                                               inplace=True)])\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         image, label = self.dataset[index]\n",
    "#         return self.trans(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b61f46b-7c1c-47f6-8ee3-d52182ebda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainValidDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "    def __len__(self):\n",
    "        return train_csv.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(path + 'train/' + train_csv['id'][index] + '.jpg')\n",
    "        label = label_list.index(train_csv['breed'][index])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bb020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = data.random_split(TrainValidDataset(),\n",
    "                                                 [9200, 10222-9200])\n",
    "train_dataset, valid_dataset = TrainDataset(train_dataset), ValidDataset(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f5a49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, size, horizontal_flip):\n",
    "        super().__init__()\n",
    "        self.trans = [transforms.Resize(size),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(mean=[0.4736, 0.4504, 0.3909],\n",
    "                                           std=[0.2655, 0.2607, 0.2650],\n",
    "                                           inplace=True)]\n",
    "        if horizontal_flip:\n",
    "            self.trans.insert(0, transforms.RandomHorizontalFlip(p=1))\n",
    "        self.trans = transforms.Compose(self.trans)\n",
    "    def __len__(self):\n",
    "        return test_csv.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(path + 'test/' + test_csv['id'][index] + '.jpg')\n",
    "        return self.trans(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f2c21ea-7af0-439b-9857-eab6db51cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmissionGenerater:\n",
    "    def __init__(self, batch_size):\n",
    "        self.sizes = [224, 256, 384, 480, 640]\n",
    "        self.datasets = []\n",
    "        for size in self.sizes:\n",
    "            self.datasets += [TestDataset(size, False), TestDataset(size, True)]\n",
    "        # 每个数据集创建一个dataloader\n",
    "        self.dataloaders = [data.DataLoader(dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=8) for dataset in self.datasets]\n",
    "    def generate(self, net):\n",
    "        net.eval()\n",
    "        outputs = {}\n",
    "        with torch.no_grad():\n",
    "            # 对每个dataloader都过一遍\n",
    "            for i, dataloader in enumerate(self.dataloaders):\n",
    "                print(f'{i+1:2d} dataset inferencing')\n",
    "                for i, input, in enumerate(dataloader):\n",
    "                    input = input.to(device)\n",
    "                    output = net(input)\n",
    "                    # 把网络的输出存储起来\n",
    "                    try:\n",
    "                        outputs[i] += F.softmax(output, dim=1)\n",
    "                    except KeyError:\n",
    "                        outputs[i] = F.softmax(output, dim=1)\n",
    "        output_tensor = torch.concat([outputs[i] for i in range(len(outputs))], dim=0)\n",
    "        print(output_tensor.shape)\n",
    "        \n",
    "        rows = []\n",
    "        column = ['id'] + label_list\n",
    "        for i in range(output_tensor.shape[0]):\n",
    "            row = [test_csv['id'][i]] + list(output_tensor[i].cpu().numpy())\n",
    "            rows.append(pd.Series(row, index=column))\n",
    "        submission = pd.DataFrame(rows)\n",
    "        \n",
    "        return submission, output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab009743-2447-482f-be37-c4e6ce73167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss_acc(net, data_iter, criterion, device=device):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度。\"\"\"\n",
    "    net.eval()  # 设置为评估模式\n",
    "    loss = []\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for input, target in data_iter:\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # output = net(input)\n",
    "            bs, ncrops, c, h, w = input.size()\n",
    "            output = net(input.view(-1, c, h, w))\n",
    "            output = output.view(bs, ncrops, -1).mean(dim=1)\n",
    "            \n",
    "            loss.append(float(criterion(output, target).item()))\n",
    "            metric.add(d2l.accuracy(output, target), target.numel())\n",
    "    return sum(loss) / len(loss), metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e7b26c4-9593-42ae-97e3-db325c172df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    return (optimizer.state_dict()['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d13c693d-8aeb-4356-bc33-d48e41ba16cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_ResNet(net,\n",
    "                 batch_size,\n",
    "                 lr,\n",
    "                 num_epochs,\n",
    "                 weight_decay=1e-4,\n",
    "                 warm_up=None):\n",
    "\n",
    "    writer = SummaryWriter(f'runs/ResNet_ImageNet_{net.architecture}_{net.option}_bn={net.batch_norm}' + ('warmup' if warm_up is not None else ''))\n",
    "    train_iter = data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                 shuffle=True, num_workers=8)\n",
    "    valid_iter = data.DataLoader(valid_dataset, batch_size=batch_size//10, \n",
    "                                 shuffle=False, num_workers=8)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "            # nn.init.normal_()\n",
    "    if warm_up is not None:\n",
    "        net.apply(init_weights)\n",
    "    optimizer = torch.optim.SGD(net.parameters(),\n",
    "                                lr=lr,\n",
    "                                weight_decay=weight_decay,\n",
    "                                momentum=0.9)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5, verbose=False)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, threshold=0.0001, verbose=True)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        tic = time.time()\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (input, target) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            input, target = input.to(device), target.to(device)\n",
    "            output = net(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(loss * input.shape[0],\n",
    "                           d2l.accuracy(output, target),\n",
    "                           input.shape[0])\n",
    "            timer.stop()\n",
    "            train_loss = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "        valid_loss, valid_acc = evaluate_loss_acc(net, valid_iter, criterion, device)\n",
    "        writer.add_scalar('train/loss', train_loss, global_step=epoch+1)\n",
    "        writer.add_scalar('train/accuracy', train_acc, global_step=epoch+1)\n",
    "        writer.add_scalar('valid/loss', valid_loss, global_step=epoch+1)\n",
    "        writer.add_scalar('valid/accuracy', valid_acc, global_step=epoch+1)\n",
    "        writer.add_scalar('learning rate', get_lr(optimizer), global_step=epoch+1)\n",
    "        # scheduler.step()\n",
    "        scheduler.step(valid_loss)\n",
    "        toc = time.time()\n",
    "        print(f\"epoch {epoch+1:3d}, train loss: {train_loss:.4f}, train accuracy: {train_acc:.4f}, \\\n",
    "valid loss: {valid_loss:.4f}, valid accuracy: {valid_acc:.4f}, time: {toc-tic:.4f}\")\n",
    "        if (warm_up is not None) and valid_acc >= warm_up:\n",
    "            break\n",
    "    if warm_up is not None:\n",
    "        torch.save(net.state_dict(),\n",
    "                   f'ResNet_ImageNet_{net.architecture}_{net.option}_bn={net.batch_norm}_warmup.pth')        \n",
    "    print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'valid loss {valid_loss:.3f}, valid acc {valid_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67a90f5-d807-43d1-a0c2-3b3e7bdf6610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23,753,912 total parameters.\n",
      "23,753,912 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "net = ResNet_ImageNet(architecture='50',\n",
    "                      num_classes = len(label_list),\n",
    "                      option='B',\n",
    "                      batch_norm=True,\n",
    "                      dropout=0.4,\n",
    "                      plain=False).to(device)\n",
    "net.print_num_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b3c1a4b-779c-4cf9-ba70-f31732bc6475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(f'ResNet_ImageNet_{net.architecture}_{net.option}_bn={net.batch_norm}_warmup.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "852fc615-d9ca-4b4e-a2ab-5666aedc31d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1, train loss: 3.4154, train accuracy: 0.1859, valid loss: 3.3845, valid accuracy: 0.1937, time: 57.2727\n",
      "epoch   2, train loss: 3.3565, train accuracy: 0.1926, valid loss: 3.1352, valid accuracy: 0.2329, time: 56.2099\n",
      "epoch   3, train loss: 3.2900, train accuracy: 0.2068, valid loss: 3.4009, valid accuracy: 0.1879, time: 56.4048\n",
      "epoch   4, train loss: 3.2816, train accuracy: 0.2097, valid loss: 3.2545, valid accuracy: 0.2104, time: 56.3249\n",
      "epoch   5, train loss: 3.2227, train accuracy: 0.2218, valid loss: 3.1680, valid accuracy: 0.2260, time: 56.3889\n",
      "epoch   6, train loss: 3.2186, train accuracy: 0.2233, valid loss: 3.2950, valid accuracy: 0.2202, time: 56.2117\n",
      "epoch   7, train loss: 3.1673, train accuracy: 0.2342, valid loss: 3.2908, valid accuracy: 0.2407, time: 56.3590\n",
      "epoch   8, train loss: 3.1359, train accuracy: 0.2315, valid loss: 3.0908, valid accuracy: 0.2554, time: 56.7769\n",
      "epoch   9, train loss: 3.0911, train accuracy: 0.2436, valid loss: 3.2840, valid accuracy: 0.2114, time: 56.2947\n",
      "epoch  10, train loss: 3.0496, train accuracy: 0.2466, valid loss: 3.2564, valid accuracy: 0.3023, time: 56.3607\n",
      "epoch  11, train loss: 3.0087, train accuracy: 0.2645, valid loss: 3.0584, valid accuracy: 0.2524, time: 56.4698\n",
      "epoch  12, train loss: 2.9560, train accuracy: 0.2670, valid loss: 2.9388, valid accuracy: 0.2466, time: 56.4104\n",
      "epoch  13, train loss: 2.9384, train accuracy: 0.2693, valid loss: 3.1290, valid accuracy: 0.2133, time: 56.6537\n",
      "epoch  14, train loss: 2.8793, train accuracy: 0.2785, valid loss: 2.8222, valid accuracy: 0.2710, time: 56.4585\n",
      "epoch  15, train loss: 2.8597, train accuracy: 0.2867, valid loss: 2.7992, valid accuracy: 0.2798, time: 56.3396\n",
      "epoch  16, train loss: 2.7984, train accuracy: 0.2968, valid loss: 2.7084, valid accuracy: 0.3004, time: 56.4756\n",
      "epoch  17, train loss: 2.7872, train accuracy: 0.3063, valid loss: 2.7870, valid accuracy: 0.2916, time: 56.4536\n",
      "epoch  18, train loss: 2.7392, train accuracy: 0.3016, valid loss: 2.6988, valid accuracy: 0.3063, time: 56.4167\n",
      "epoch  19, train loss: 2.7234, train accuracy: 0.3068, valid loss: 2.7051, valid accuracy: 0.3112, time: 56.3611\n",
      "epoch  20, train loss: 2.6905, train accuracy: 0.3225, valid loss: 2.6651, valid accuracy: 0.3307, time: 56.4221\n",
      "epoch  21, train loss: 2.6484, train accuracy: 0.3340, valid loss: 2.6884, valid accuracy: 0.2984, time: 56.4911\n",
      "epoch  22, train loss: 2.6161, train accuracy: 0.3355, valid loss: 2.8249, valid accuracy: 0.2877, time: 56.3842\n",
      "epoch  23, train loss: 2.5799, train accuracy: 0.3426, valid loss: 2.6980, valid accuracy: 0.3102, time: 56.6403\n",
      "epoch  24, train loss: 2.5710, train accuracy: 0.3429, valid loss: 2.6844, valid accuracy: 0.2935, time: 56.3934\n",
      "epoch  25, train loss: 2.4975, train accuracy: 0.3603, valid loss: 2.3546, valid accuracy: 0.3757, time: 56.4182\n",
      "epoch  26, train loss: 2.4865, train accuracy: 0.3583, valid loss: 3.0514, valid accuracy: 0.2231, time: 56.5935\n",
      "epoch  27, train loss: 2.4586, train accuracy: 0.3640, valid loss: 2.7141, valid accuracy: 0.3053, time: 56.4898\n",
      "epoch  28, train loss: 2.4214, train accuracy: 0.3746, valid loss: 2.5318, valid accuracy: 0.3288, time: 56.3459\n",
      "epoch  29, train loss: 2.3823, train accuracy: 0.3863, valid loss: 2.3275, valid accuracy: 0.3757, time: 56.3679\n",
      "epoch  30, train loss: 2.3439, train accuracy: 0.3839, valid loss: 2.5933, valid accuracy: 0.3141, time: 56.3844\n",
      "epoch  31, train loss: 2.3447, train accuracy: 0.3921, valid loss: 2.5165, valid accuracy: 0.3532, time: 56.4659\n",
      "epoch  32, train loss: 2.3043, train accuracy: 0.3942, valid loss: 2.3449, valid accuracy: 0.3806, time: 56.4074\n",
      "epoch  33, train loss: 2.2962, train accuracy: 0.4104, valid loss: 2.4380, valid accuracy: 0.3728, time: 56.5302\n",
      "epoch  34, train loss: 2.2574, train accuracy: 0.4082, valid loss: 2.4438, valid accuracy: 0.3640, time: 56.5462\n",
      "epoch  35, train loss: 2.2181, train accuracy: 0.4180, valid loss: 2.4632, valid accuracy: 0.3689, time: 56.8275\n",
      "epoch  36, train loss: 2.2293, train accuracy: 0.4104, valid loss: 2.3987, valid accuracy: 0.3738, time: 56.3271\n",
      "epoch  37, train loss: 2.1693, train accuracy: 0.4249, valid loss: 2.9086, valid accuracy: 0.2877, time: 56.5329\n",
      "epoch  38, train loss: 2.1979, train accuracy: 0.4197, valid loss: 2.3065, valid accuracy: 0.3875, time: 56.5214\n",
      "epoch  39, train loss: 2.1564, train accuracy: 0.4303, valid loss: 2.5278, valid accuracy: 0.3523, time: 56.4207\n",
      "epoch  40, train loss: 2.1178, train accuracy: 0.4457, valid loss: 2.2890, valid accuracy: 0.3885, time: 56.4780\n",
      "epoch  41, train loss: 2.0995, train accuracy: 0.4426, valid loss: 3.0106, valid accuracy: 0.2798, time: 56.2714\n",
      "epoch  42, train loss: 2.0803, train accuracy: 0.4455, valid loss: 2.6820, valid accuracy: 0.3209, time: 56.5026\n",
      "epoch  43, train loss: 2.0604, train accuracy: 0.4555, valid loss: 2.2353, valid accuracy: 0.4149, time: 56.4017\n",
      "epoch  44, train loss: 1.9960, train accuracy: 0.4636, valid loss: 2.7373, valid accuracy: 0.3063, time: 56.4295\n",
      "epoch  45, train loss: 2.0026, train accuracy: 0.4705, valid loss: 2.3820, valid accuracy: 0.3855, time: 56.3353\n",
      "epoch  46, train loss: 1.9754, train accuracy: 0.4792, valid loss: 2.2537, valid accuracy: 0.3885, time: 56.3725\n",
      "epoch  47, train loss: 1.9342, train accuracy: 0.4850, valid loss: 2.6418, valid accuracy: 0.3239, time: 56.3708\n",
      "epoch  48, train loss: 1.9077, train accuracy: 0.4948, valid loss: 2.1962, valid accuracy: 0.4247, time: 56.3648\n",
      "epoch  49, train loss: 1.9069, train accuracy: 0.4884, valid loss: 2.1913, valid accuracy: 0.4022, time: 56.3068\n",
      "epoch  50, train loss: 1.8695, train accuracy: 0.4972, valid loss: 2.4048, valid accuracy: 0.3444, time: 56.5034\n",
      "epoch  51, train loss: 1.8358, train accuracy: 0.5103, valid loss: 2.2951, valid accuracy: 0.4159, time: 56.3957\n",
      "epoch  52, train loss: 1.8292, train accuracy: 0.5105, valid loss: 2.2521, valid accuracy: 0.4129, time: 56.7414\n",
      "epoch  53, train loss: 1.8162, train accuracy: 0.5126, valid loss: 2.3550, valid accuracy: 0.4051, time: 56.3929\n",
      "epoch  54, train loss: 1.7935, train accuracy: 0.5148, valid loss: 2.2534, valid accuracy: 0.3885, time: 56.3129\n",
      "epoch  55, train loss: 1.8105, train accuracy: 0.5129, valid loss: 2.2710, valid accuracy: 0.4022, time: 56.5224\n",
      "epoch  56, train loss: 1.7748, train accuracy: 0.5230, valid loss: 2.2940, valid accuracy: 0.4168, time: 56.4109\n",
      "epoch  57, train loss: 1.7320, train accuracy: 0.5342, valid loss: 2.1030, valid accuracy: 0.4579, time: 56.7747\n",
      "epoch  58, train loss: 1.7265, train accuracy: 0.5310, valid loss: 2.3657, valid accuracy: 0.3943, time: 57.5307\n",
      "epoch  59, train loss: 1.6738, train accuracy: 0.5438, valid loss: 2.1019, valid accuracy: 0.4374, time: 56.4145\n",
      "epoch  60, train loss: 1.6943, train accuracy: 0.5433, valid loss: 2.1549, valid accuracy: 0.4237, time: 56.2764\n",
      "epoch  61, train loss: 1.6511, train accuracy: 0.5557, valid loss: 2.4384, valid accuracy: 0.3748, time: 56.3517\n",
      "epoch  62, train loss: 1.6618, train accuracy: 0.5536, valid loss: 2.3472, valid accuracy: 0.3914, time: 56.5839\n",
      "epoch  63, train loss: 1.6636, train accuracy: 0.5525, valid loss: 2.0186, valid accuracy: 0.4550, time: 56.3988\n",
      "epoch  64, train loss: 1.6284, train accuracy: 0.5543, valid loss: 2.2030, valid accuracy: 0.4207, time: 56.6339\n",
      "epoch  65, train loss: 1.6100, train accuracy: 0.5635, valid loss: 2.1054, valid accuracy: 0.4256, time: 56.8866\n",
      "epoch  66, train loss: 1.5922, train accuracy: 0.5680, valid loss: 2.0112, valid accuracy: 0.4628, time: 56.4542\n",
      "epoch  67, train loss: 1.5387, train accuracy: 0.5825, valid loss: 2.1600, valid accuracy: 0.4159, time: 56.5256\n",
      "epoch  68, train loss: 1.5414, train accuracy: 0.5882, valid loss: 2.0603, valid accuracy: 0.4530, time: 56.4270\n",
      "epoch  69, train loss: 1.4934, train accuracy: 0.5884, valid loss: 2.3174, valid accuracy: 0.4110, time: 56.3035\n",
      "epoch  70, train loss: 1.5283, train accuracy: 0.5815, valid loss: 2.5183, valid accuracy: 0.3268, time: 56.4246\n",
      "epoch  71, train loss: 1.5140, train accuracy: 0.5860, valid loss: 2.0393, valid accuracy: 0.4432, time: 56.3621\n",
      "epoch  72, train loss: 1.4747, train accuracy: 0.6004, valid loss: 2.1415, valid accuracy: 0.4579, time: 56.8648\n",
      "epoch  73, train loss: 1.4572, train accuracy: 0.6010, valid loss: 2.3187, valid accuracy: 0.4022, time: 56.9430\n",
      "epoch  74, train loss: 1.4466, train accuracy: 0.6047, valid loss: 2.2597, valid accuracy: 0.4295, time: 57.2880\n",
      "epoch  75, train loss: 1.4067, train accuracy: 0.6199, valid loss: 1.9697, valid accuracy: 0.4667, time: 57.4537\n",
      "epoch  76, train loss: 1.4171, train accuracy: 0.6132, valid loss: 2.0200, valid accuracy: 0.4569, time: 58.6838\n",
      "epoch  77, train loss: 1.4080, train accuracy: 0.6226, valid loss: 2.2478, valid accuracy: 0.4139, time: 58.3234\n",
      "epoch  78, train loss: 1.4026, train accuracy: 0.6173, valid loss: 2.0412, valid accuracy: 0.4599, time: 58.8463\n",
      "epoch  79, train loss: 1.3667, train accuracy: 0.6305, valid loss: 1.9519, valid accuracy: 0.4755, time: 58.3182\n",
      "epoch  80, train loss: 1.3644, train accuracy: 0.6303, valid loss: 1.9692, valid accuracy: 0.4658, time: 57.4752\n",
      "epoch  81, train loss: 1.3433, train accuracy: 0.6304, valid loss: 2.1454, valid accuracy: 0.4491, time: 56.1956\n",
      "epoch  82, train loss: 1.3319, train accuracy: 0.6389, valid loss: 2.0362, valid accuracy: 0.4618, time: 57.3966\n",
      "epoch  83, train loss: 1.3323, train accuracy: 0.6337, valid loss: 2.1289, valid accuracy: 0.4442, time: 57.9513\n",
      "epoch  84, train loss: 1.3403, train accuracy: 0.6367, valid loss: 2.0757, valid accuracy: 0.4442, time: 56.6283\n",
      "epoch  85, train loss: 1.2667, train accuracy: 0.6558, valid loss: 1.8841, valid accuracy: 0.4863, time: 57.2446\n",
      "epoch  86, train loss: 1.2759, train accuracy: 0.6533, valid loss: 2.0574, valid accuracy: 0.4638, time: 57.2786\n",
      "epoch  87, train loss: 1.2658, train accuracy: 0.6548, valid loss: 2.0423, valid accuracy: 0.4530, time: 58.0179\n",
      "epoch  88, train loss: 1.2553, train accuracy: 0.6586, valid loss: 2.4392, valid accuracy: 0.3885, time: 57.6807\n",
      "epoch  89, train loss: 1.2538, train accuracy: 0.6557, valid loss: 1.9028, valid accuracy: 0.4814, time: 58.9715\n",
      "epoch  90, train loss: 1.2321, train accuracy: 0.6645, valid loss: 1.7612, valid accuracy: 0.5186, time: 57.6073\n",
      "epoch  91, train loss: 1.2102, train accuracy: 0.6698, valid loss: 2.0453, valid accuracy: 0.4481, time: 57.1947\n",
      "epoch  92, train loss: 1.2174, train accuracy: 0.6700, valid loss: 2.1627, valid accuracy: 0.4374, time: 58.2425\n",
      "epoch  93, train loss: 1.1749, train accuracy: 0.6751, valid loss: 2.2624, valid accuracy: 0.4286, time: 56.8015\n",
      "epoch  94, train loss: 1.1565, train accuracy: 0.6810, valid loss: 1.8657, valid accuracy: 0.5196, time: 56.2509\n",
      "epoch  95, train loss: 1.1840, train accuracy: 0.6824, valid loss: 2.2262, valid accuracy: 0.4266, time: 56.2913\n",
      "epoch  96, train loss: 1.1592, train accuracy: 0.6867, valid loss: 1.8439, valid accuracy: 0.5000, time: 56.3874\n",
      "epoch  97, train loss: 1.1454, train accuracy: 0.6845, valid loss: 1.8926, valid accuracy: 0.4990, time: 57.3250\n",
      "epoch  98, train loss: 1.1193, train accuracy: 0.6952, valid loss: 2.0764, valid accuracy: 0.4726, time: 58.6961\n",
      "epoch  99, train loss: 1.1518, train accuracy: 0.6914, valid loss: 1.8889, valid accuracy: 0.4824, time: 57.8151\n",
      "epoch 100, train loss: 1.1716, train accuracy: 0.6834, valid loss: 2.3134, valid accuracy: 0.4237, time: 59.6829\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-03.\n",
      "epoch 101, train loss: 1.1135, train accuracy: 0.7008, valid loss: 1.9720, valid accuracy: 0.5010, time: 57.7325\n",
      "epoch 102, train loss: 0.8776, train accuracy: 0.7688, valid loss: 1.4511, valid accuracy: 0.5978, time: 58.0271\n",
      "epoch 103, train loss: 0.7436, train accuracy: 0.8110, valid loss: 1.4128, valid accuracy: 0.5959, time: 57.5202\n",
      "epoch 104, train loss: 0.7123, train accuracy: 0.8203, valid loss: 1.3966, valid accuracy: 0.6037, time: 56.7202\n",
      "epoch 105, train loss: 0.7065, train accuracy: 0.8221, valid loss: 1.3821, valid accuracy: 0.6057, time: 56.3954\n",
      "epoch 106, train loss: 0.6746, train accuracy: 0.8314, valid loss: 1.3953, valid accuracy: 0.6027, time: 56.2400\n",
      "epoch 107, train loss: 0.6544, train accuracy: 0.8370, valid loss: 1.4010, valid accuracy: 0.6008, time: 56.4289\n",
      "epoch 108, train loss: 0.6331, train accuracy: 0.8427, valid loss: 1.3805, valid accuracy: 0.6115, time: 57.1914\n",
      "epoch 109, train loss: 0.6334, train accuracy: 0.8396, valid loss: 1.3939, valid accuracy: 0.6047, time: 58.2353\n",
      "epoch 110, train loss: 0.6224, train accuracy: 0.8433, valid loss: 1.3891, valid accuracy: 0.6047, time: 57.4422\n",
      "epoch 111, train loss: 0.5969, train accuracy: 0.8526, valid loss: 1.3968, valid accuracy: 0.6067, time: 56.4166\n",
      "epoch 112, train loss: 0.5950, train accuracy: 0.8480, valid loss: 1.3976, valid accuracy: 0.6047, time: 56.3274\n",
      "epoch 113, train loss: 0.6037, train accuracy: 0.8514, valid loss: 1.3862, valid accuracy: 0.6076, time: 56.3131\n",
      "epoch 114, train loss: 0.5752, train accuracy: 0.8567, valid loss: 1.3741, valid accuracy: 0.6233, time: 57.4629\n",
      "epoch 115, train loss: 0.5866, train accuracy: 0.8545, valid loss: 1.3854, valid accuracy: 0.6164, time: 56.5484\n",
      "epoch 116, train loss: 0.5619, train accuracy: 0.8614, valid loss: 1.3910, valid accuracy: 0.6164, time: 57.9887\n",
      "epoch 117, train loss: 0.5991, train accuracy: 0.8534, valid loss: 1.3767, valid accuracy: 0.6164, time: 56.5119\n",
      "epoch 118, train loss: 0.5798, train accuracy: 0.8560, valid loss: 1.4055, valid accuracy: 0.6135, time: 56.5670\n",
      "epoch 119, train loss: 0.5409, train accuracy: 0.8649, valid loss: 1.3878, valid accuracy: 0.6076, time: 56.9112\n",
      "epoch 120, train loss: 0.5495, train accuracy: 0.8640, valid loss: 1.3761, valid accuracy: 0.6184, time: 56.5297\n",
      "epoch 121, train loss: 0.5585, train accuracy: 0.8643, valid loss: 1.3816, valid accuracy: 0.6184, time: 56.5568\n",
      "epoch 122, train loss: 0.5305, train accuracy: 0.8700, valid loss: 1.3829, valid accuracy: 0.6262, time: 56.4923\n",
      "epoch 123, train loss: 0.5508, train accuracy: 0.8621, valid loss: 1.3885, valid accuracy: 0.6282, time: 56.4234\n",
      "epoch 124, train loss: 0.5454, train accuracy: 0.8625, valid loss: 1.3696, valid accuracy: 0.6252, time: 56.3890\n",
      "epoch 125, train loss: 0.5333, train accuracy: 0.8640, valid loss: 1.3834, valid accuracy: 0.6194, time: 56.4912\n",
      "epoch 126, train loss: 0.5151, train accuracy: 0.8711, valid loss: 1.3725, valid accuracy: 0.6282, time: 56.4922\n",
      "epoch 127, train loss: 0.5326, train accuracy: 0.8705, valid loss: 1.4003, valid accuracy: 0.6086, time: 56.4921\n",
      "epoch 128, train loss: 0.4951, train accuracy: 0.8796, valid loss: 1.3857, valid accuracy: 0.6135, time: 56.5364\n",
      "epoch 129, train loss: 0.5226, train accuracy: 0.8720, valid loss: 1.3792, valid accuracy: 0.6155, time: 56.4786\n",
      "epoch 130, train loss: 0.5014, train accuracy: 0.8784, valid loss: 1.3902, valid accuracy: 0.6145, time: 56.8049\n",
      "epoch 131, train loss: 0.4884, train accuracy: 0.8802, valid loss: 1.3973, valid accuracy: 0.6057, time: 56.4474\n",
      "epoch 132, train loss: 0.4962, train accuracy: 0.8774, valid loss: 1.3980, valid accuracy: 0.6125, time: 56.5516\n",
      "epoch 133, train loss: 0.4992, train accuracy: 0.8745, valid loss: 1.4025, valid accuracy: 0.6037, time: 56.5668\n",
      "epoch 134, train loss: 0.4989, train accuracy: 0.8774, valid loss: 1.3896, valid accuracy: 0.6018, time: 56.5038\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-04.\n",
      "epoch 135, train loss: 0.4941, train accuracy: 0.8811, valid loss: 1.3748, valid accuracy: 0.6194, time: 56.4687\n",
      "epoch 136, train loss: 0.4699, train accuracy: 0.8877, valid loss: 1.3743, valid accuracy: 0.6204, time: 56.5614\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_274987/1909420565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_ResNet(net,\n\u001b[0m\u001b[1;32m      2\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              weight_decay=1e-3)\n",
      "\u001b[0;32m/tmp/ipykernel_274987/3890301126.py\u001b[0m in \u001b[0;36mtrain_ResNet\u001b[0;34m(net, batch_size, lr, num_epochs, weight_decay, warm_up)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_loss_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train/loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train/accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_274987/2826177418.py\u001b[0m in \u001b[0;36mevaluate_loss_acc\u001b[0;34m(net, data_iter, criterion, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ResNet(net,\n",
    "             batch_size=128,\n",
    "             lr=0.01,\n",
    "             num_epochs=150,\n",
    "             weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "117d6aba-29ea-4d0a-a3f3-74d7b61d6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), f'ResNet_ImageNet_{net.architecture}_{net.option}_bn={net.batch_norm}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a215846-0885-4c93-93bb-86d889c5f1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(f'ResNet_ImageNet_{net.architecture}_{net.option}_bn={net.batch_norm}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfae30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generater = SubmissionGenerater(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc68fef8-36d1-47ef-b43c-31f0246937ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 dataset inferencing\n",
      " 2 dataset inferencing\n",
      " 3 dataset inferencing\n",
      " 4 dataset inferencing\n",
      " 5 dataset inferencing\n",
      " 6 dataset inferencing\n",
      " 7 dataset inferencing\n",
      " 8 dataset inferencing\n",
      " 9 dataset inferencing\n",
      "10 dataset inferencing\n",
      "torch.Size([10357, 120])\n"
     ]
    }
   ],
   "source": [
    "submission, output_tensor = generater.generate(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0971770-4838-4672-b543-ad54124c19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'submission_{net.architecture}_{net.option}_bn={net.batch_norm}_plain={net.plain}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
