

# Week 2 GoogLeNet论文笔记+复现

论文地址：

- 本地（做了标记）[Going deeper with convolutions](../papers/GoogLenet.pdf)
- 原地址[Going deeper with convolutions](arxiv.org/pdf/1409.4842.pdf)

上期回顾：[Week 1 VGG](../Week1-VGG/Week 1 VGG.md)



## Abstract

​		新发明的GoogLeNet，在ILSVRC-2014的图片分类和目标检测中都成为了SOTA。最突出的优点是GoogLeNet能在增加网络深度和宽度的情况下，维持计算量较小。



## 1 Introduction

​		在ILSVRC-2014的提交中，GoogLeNet的参数数量是AlexNet的1/12，但精度显著增加。当时深度学习在移动端和嵌入式设备中的应用使得模型的效率、性能和内存占用变得越来越重要，所以作者在设计这个网络架构的时候不仅评估了精度，而是内存、计算量等因素也纳入考虑。在大多数实验中，模型被设计成在推理时大约需要15亿次相乘相加运算，因此这个模型不仅仅可以被用来做学术研究，而是能够在现实生活中被应用起来。

​		本文提出的新结构Inception的名字是从电影《盗梦空间》衍生出的“we need to go deeper”网络meme中得来的。这张梗图甚至是原论文的第一个引用。

![img](..\pictures\we need to go deeper.png)

​		作者说，这里的"deep"有两层含义：一指Inception代表在探索CNN新架构上达到了更高的地步，二单纯指网络的深度变得更大了。



## 2 Related Work

​		LeNet定义了CNN的传统架构：叠加在一起的卷积层，每个卷积层后面可选地接着归一化层和池化层，最后是一个或多个全连接层。这种传统架构及其变种在MNIST、CIFAR等小型数据集上都获得了最佳的成绩。在ImageNet等大型数据集上，CNN的发展趋势是增加网络的深度和宽度，同时添加Dropout层来避免过拟合。

​		和本文介绍的Inception结构相似，为了检测多尺度特征，有的工作在一层中用了一系列不同大小的Gabor滤波器。但其网络与本文的Inception结构不同之处在于，Inception结构中的所有参数都是学习而来的，并且Inception块在网络中叠加了多次，最终产生了一个22层的GoogLeNet。

​		为了提升网络的表达能力，NiN使用了额外的1\*1卷积层和激活函数。但在本文所提出的架构中，**1\*1卷积层有不同的用处：降低特征图的通道数以减少计算量；引入额外的非线性性，使得网络的表达能力更强。**这使得在不增加太多计算量的情况下，同时增加网络的宽度和深度成为可能。

​		目标检测领域，目前最好的工作是R-CNN。R-CNN将整个目标检测工作分成两个部分：首先利用图像的低级特征来提出可能带有物体的部分类别的感兴趣区域，随后再用强大的CNN来识别感兴趣区域中物体的种类。本文在此基础上优化了这两个阶段。



## 3 Motivation and High Level Considerations

​		提升网络性能最直接的方法无非增加网络的深度——网络的层数和网络的宽度——每层的单元个数（通道数）。在有足够大的数据集可用的情况下，这样做是简单且安全的。但这个做法缺点有二：数据集大小受限时，大型网络将遭受严重的过拟合；略微增加大型网络的大小，所需的计算量将会急剧增加。

​		同时解决这两个问题的基本方法就是从紧密连接的全连接结构转向稀疏连接的结构。Arora等人的工作提出：如果一个数据集的概率分布可以用一个深且稀疏的神经网络来表达，那么最优化的拓扑结构可以通过逐层分析上一层网络激活值的统计相关性，并对输出相关性强的神经元进行聚类来构建。尽管文中为了证明这一结论，做了较强的假设，核心思想可以通过著名的Hebbian principle来理解："**neurons that fire together, wire together**"，说的是行为相似的两个神经元应当有更加紧密的联系。尽管实际使用中很难达到较强的假设，这个原则背后的核心思想仍然适用。

​		不幸的是，如今的计算设施在不均匀的稀疏数据结构上的计算效率极其低下。尽管由于稀疏性，数值计算操作减少了一百倍以上，但访存和缓存命中率低等问题都使得为了获得稀疏性而去使用稀疏矩阵变得不值当。大部分的视觉任务中都仅仅依靠卷积来获得稀疏性。

​		这不禁让人想问：有没有一种结构，能获得额外的稀疏性，并且能在当前的硬件条件下进行高效的计算？在稀疏矩阵计算领域，一个可选的做法就是将稀疏矩阵分解成许多更加密集的子矩阵后分别计算。Inception就是这样的一种对Arora所提出的架构的模仿（见第4节）。看起来很凑巧，但Inception确实仅在两个迭代周期后就展现出了比NiN更强大的性能。

​		作者警告：尽管这样的架构在计算机视觉领域表现突出，优越的性能是否仅归功于产生此架构的背后的指导原则也是需要进一步研究的。如果基于这一指导原则在其他的领域产生了看起来网络架构截然不同，但核心思想相同的网络，那么就能够确信是这一指导原则带来了如此优越的性能。至少Inception的成功带来了这一方向研究的希望。

​		**但是！李沐和吴恩达的课程中在介绍GoogLeNet的时候只字未提稀疏性，均是从如下角度来解释为何Inception性能优越：网络的各种卷积、池化层选择众多，与其人工选择最优的层，不如全部使用，四个路径从不同层面抽取信息，在输出通道上合并，具体使用哪些卷积核的信息交给下一层决定。**



## 4 Architecture Details

​		核心思想是遵循Arora等人提出的原则，用卷积层构造一个稀疏的局部结构，然后把它叠上好几层。回忆Arora等人提出的原则，应当分析最后一层的输出，并把输出相关性强的神经元聚类形成下一层的神经元并和上一层的神经元进行连接。在神经网络的浅层，输出相关性强的神经元应当集中在局部区域上。这意味着我们会得到大量各自集中在输入图片单个区域上的簇，这些簇可以通过下一层的1\*1卷积来融合。同时，由于浅层网络低级特征的局部性，可以想象到单个簇中的各个卷积核的激活位置在空间上分得较开的情况应该较少——这些簇可以通过较大的卷积核尺寸来覆盖，并且这种簇应该随着网络的加深而变得越来越少，因为深层网络一般检测的是较为抽象的特征。随着Inception块的叠加，网络的深度变得越来越大。深层网络中检测的特征更加抽象，语义性更强，空间集中性也应当比底层网络更弱，因此随着网络深度变大，深层中3\*3和5\*5卷积的数量应该有所增加。另外，池化层也是现如今SOTA必不可少的一个模块，因此在Inception结构中单独开辟一个并行池化路径。

![GoogLeNet-Figure2](..\pictures\GoogLeNet-Figure2.png)

​		第一次看第4节的第一大段我真的很懵比。。。基本上完全没看懂。吃了个晚饭回来突然明白一点了，在这里解释一下：

​		Inception结构各个分支的输出是在通道维拼接起来的。在浅层网络中，由于浅层特征较为低级（如色彩或亮度的突变、简单的纹理等），对于激活值相关性较高（检测的特征相似）的卷积核，激活值所处的位置应该也相近甚至重合，这样的卷积核簇就可以在下一层通过一个1\*1卷积来合并成一个通道；在网络的深层，特征比较高级，激活值相关性较高的卷积核，一般检测的特征在语义层面关联度较高（例如人的眼睛和鼻子等经常在画面中同时出现的事物），但空间位置一般不同，所以这样的卷积核簇在下一层需要使用3\*3甚至5\*5的卷积核来合并成一个通道。

​		图2(a)中的结构有一个大问题：少得不能再少的5\*5卷积也会带来巨大的计算量。特别是如果上一层包含了最大池化分支（这个分支的输出通道数等于输入通道数）时，问题就显得尤为明显。如果不加图2(b)中的1\*1卷积以减少通道数，计算量在叠加几层之后就会很快增长到无法接受的水平。值得注意的是，图2(b)中每个黄色的1\*1卷积层后都跟随着一个ReLU激活函数，这使得它**不仅能够降低通道数，还引入了额外的非线性性，增强了网络的表达能力。**因此，每个Inception仅改变特征图通道数，不改变特征图的尺寸。下采样由一些Inception块之间的2\*2，s=2的最大池化层来完成。

​		**值得注意的是，3\*3和5\*5卷积的输出通道数常常多于在其之前的1\*1卷积的输出通道数，这使得1\*1卷积形成了一个瓶颈，但只要输出通道数设定合理，就不会给网络性能造成伤害。**

​		为了更高效地使用内存，作者发现最好在浅层保持传统的CNN架构，在网络深层再使用Inception块，但这不是必要的。

​		另外，GoogLeNet的一大有点就是可以显著的增加某层的通道数，计算复杂度却不会像传统CNN结构一样爆炸式增长。这是由于每个Inception块中3\*3卷积层和5\*5卷积层前的1\*1卷积层就像一个通道隔断层一样，固定了其输出的通道数，阻碍前面Inception块的巨幅通道增长对后面的Inception块产生太多影响，这也使得GoogLeNet比性能相似的非Inception结构的网络效率快2-3倍。



## 5 GoogLeNet

​		L大写是作者在致敬LeNet。GoogLeNet的架构见表1：

![GoogLeNet-Table1](..\pictures\GoogLeNet-Table1.png)

​		其中，#3\*3 reduce 和 #5\*5 reduce 是对应3\*3或5\*5卷积层前的全连接层。虽然网络最后也用了和NiN相同的全局平均池化层，但和NiN不同，在全局平均池化层之后作者添加了额外的全连接层，纯粹是因为这能使得使用GoogLeNet做微调更加方便（丢弃这个全连接层之后top-1错误率降低了0.6%），因为若不加这个全连接层而直接将全局平均池化的输出作为softmax得输入，最后一个Inception块输出的几乎就是类别信息了，这使得在微调任务中就不得不丢弃最后一个Inception块不用。

​		所有的卷积层和全连接层之后都跟有ReLU激活函数。

​		网络深度较大，为了浅层的参数也能顺利更新，作者在网络的中间部分（Inception块4b前和4e前）还嵌入了两个额外的分类器，以期梯度能够通过额外的分类器向浅层顺利传播。为了达到这一目的，作者将中间分类器的损失函数以0.3的权重加到了总损失函数上。**在测试阶段，中间分类器弃置不用。**

![inception-full](..\pictures\inception-full.svg)



## 6 Training Methodology

​		损失函数：交叉熵

​		优化算法：SGD

​		lr_scheduler：每8个epoch降低4%学习率

​		momentum=0.9

​		每次从原图中抠出占原图面积8%~100%的一块，长宽比在3/4~4/3之间随机取值。

​		作者的图片采样策略在几个月的备赛过程中发生了大幅度的转变，并且已经收敛的模型在训练的过程中也使用了多种超参数结合的策略，所以很难给出一个确切的最有超参数组合。



## 7 ILSVRC 2014 Classification Challenge Setup and Results

​		除去上文提到的一些训练技巧，作者还用了一些技巧来提升测试性能：

1.   用了7模型融合。这7个模型的初始权重甚至都是一样的，仅在数据采样方法上有所区别。
2.   在测试时，作者使用了一种更加激进的裁剪策略：将短边缩放为4个尺寸[256, 288, 320, 352]。随后，对于宽而矮的图片，裁出左中右三个正方形；对于窄而高的图片，裁出上中下三个正方形。对于每个正方形子图，在四个角落和正中央裁出五张224\*224的图片，并把原正方形子图缩放为224\*224，共6张图片，及其水平翻转版本。一张图片共产生4\*3\*6\*2=144张测试样本。
3.   最后将这144张图片的softmax值做平均，再对各个分类器做平均。

![GoogLeNet-Table2](..\pictures\GoogLeNet-Table2.png)

![GoogLeNet-Table3](..\pictures\GoogLeNet-Table3.png)

​		可以看到，表现最佳的7模型融合+144crops确实比base好了不少，但计算量几乎是1000倍之多。作者也提到，实际使用中，无需如此激进的crop方法。



## 8 ILSVRC 2014 Detection Challenge Setup and Results

​		ILSVRC的目标检测比赛中共有200个类别。当预测框和GT框的IOU大于等于50%且类别预测正确时，才算做预测成功。一张图片里可能有多个物体也可能没有物体，物体有大有小。

​		GoogLeNet的目标检测策略类似于R-CNN，但在分类器中使用了带有Inception块的网络，并且在区域提取阶段使用了选择性搜索（Selective Search）的启发式。为了提高查全率使用了multi-box prediction。为了降低假阳性，将superpixel的尺寸提高了一倍，这也使得区域提取的输出减少了一半。

​		GoogLeNet用了额外的数据（ILSVRC2012）来预训练特征提取网络，但没有使用额外的目标检测数据来训练。



## 9 Conclusions

​		GoogLeNet在计算量相比更浅、更窄的网络增加不太多的情况下实现了巨幅的精度提升，这也证明了稀疏的网络结构是可行的。



## 总结

### 	贡献

​		设计了含并行计算的网络结构：Inception块，在计算量和参数数量都较小的情况下展现出了较强的性能。

<img src="..\pictures\Inception block v.s. conv layer.png" alt="Inception block v.s. conv layer" style="zoom:50%;" />

### 	动机

​		在保证精度的情况下缩减内存使用和计算量，使得网络可以部署在移动设备和嵌入式设备中；设计稀疏的结构，使得网络能在现有适用于密集性计算的设备上高效地计算。

### 	结构

​		Inception块：1\*1卷积、1\*1卷积 -> 3\*3卷积、1\*1卷积 -> 5\*5卷积、3\*3最大池化 -> 1\*1卷积

### 	预处理

​		训练：每次从原图中抠出占原图面积8%~100%的一块，长宽比在3/4~4/3之间随机取值。

​		预测：4个尺寸，每个尺寸3个正方形剪裁，每个正方形子图产生6个图片，每个图片水平翻转一次，共144张图片。

