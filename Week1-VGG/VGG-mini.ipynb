{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18877a22-edf4-4bbe-9152-2bb4123fdd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4983f08c-f416-4ac9-b564-333de7fd94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 百度来的，不然下载不动。。\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74791bf-2fb3-497a-81e6-1533a77e32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = [0.491, 0.482, 0.446], [0.247, 0.243, 0.261]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f78c5ac-c033-4389-9b71-606cab7cd7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, S):\n",
    "        super().__init__()\n",
    "        self.dataset = torchvision.datasets.CIFAR10(\n",
    "            root=\"../data\", train=True, download=True)\n",
    "        \n",
    "        self.S = S\n",
    "        \n",
    "        self.trans = [transforms.RandomCrop(64),\n",
    "                      transforms.RandomHorizontalFlip(p=0.5),\n",
    "                      transforms.ColorJitter(brightness=0.1,\n",
    "                                             contrast=0.1,\n",
    "                                             saturation=0.1,\n",
    "                                             hue=0),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(mean, std, inplace=True)]\n",
    "        self.trans = transforms.Compose(self.trans)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(self.S, int):\n",
    "            resize = transforms.Resize(max(64, self.S))\n",
    "        elif isinstance(self.S, list):\n",
    "            assert(len(self.S) == 2)\n",
    "            resize = transforms.Resize(\n",
    "                random.randint(self.S[0], self.S[1]))\n",
    "\n",
    "        return (self.trans(resize(self.dataset[index][0])),\n",
    "                self.dataset[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba014a6-ec42-4bde-bd30-2076667af194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, Q, horizontal_flip=False):\n",
    "        super().__init__()\n",
    "        self.dataset = torchvision.datasets.CIFAR10(\n",
    "            root=\"../data\", train=False, download=True)\n",
    "        \n",
    "        self.Q = Q\n",
    "        \n",
    "        self.trans = [transforms.ToTensor(),\n",
    "                      transforms.Normalize(mean, std, inplace=True)]\n",
    "        if horizontal_flip:\n",
    "            self.trans.insert(0, transforms.RandomHorizontalFlip(p=1))\n",
    "        self.trans = transforms.Compose(self.trans)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        assert(isinstance(self.Q, int))\n",
    "        resize = transforms.Resize(max(64, self.Q))\n",
    "            \n",
    "        return (self.trans(resize(self.dataset[index][0])),\n",
    "                self.dataset[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c237404-4b93-4f82-b1c7-634c69255afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_3x3, conv_1x1=False, batch_norm=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels, out_channels,\n",
    "                             kernel_size=3, stride=1, padding=1),\n",
    "                   nn.BatchNorm2d(out_channels),\n",
    "                   nn.ReLU(inplace=True)] if batch_norm else \\\n",
    "                  [nn.Conv2d(in_channels, out_channels,\n",
    "                             kernel_size=3, stride=1, padding=1),\n",
    "                   nn.ReLU(inplace=True)]\n",
    "        if num_3x3 > 1:\n",
    "            for i in range(1, num_3x3):\n",
    "                layers += [nn.Conv2d(out_channels, out_channels,\n",
    "                                     kernel_size=3, stride=1, padding=1),\n",
    "                           nn.BatchNorm2d(out_channels),\n",
    "                           nn.ReLU(inplace=True)] if batch_norm else \\\n",
    "                          [nn.Conv2d(out_channels, out_channels,\n",
    "                                     kernel_size=3, stride=1, padding=1),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "        if conv_1x1:\n",
    "            layers += [nn.Conv2d(out_channels, out_channels,\n",
    "                                 kernel_size=1, stride=1, padding=0),\n",
    "                       nn.BatchNorm2d(out_channels),\n",
    "                       nn.ReLU(inplace=True)] if batch_norm else \\\n",
    "                      [nn.Conv2d(out_channels, out_channels,\n",
    "                                 kernel_size=1, stride=1, padding=0),\n",
    "                       nn.ReLU(inplace=True)]\n",
    "        layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        \n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.block(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f85038-4d69-4c07-aecb-3f5a49f9a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_mini(nn.Module):\n",
    "    def __init__(self, configuration, batch_norm=False, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.configurations = {\n",
    "            'A': [[3,   8,  1, False],\n",
    "                  [8,   16, 1, False],\n",
    "                  [16,  32, 2, False],\n",
    "                  [32,  64, 2, False],\n",
    "                  [64,  64, 2, False]],\n",
    "            \n",
    "            'B': [[3,   8,  2, False],\n",
    "                  [8,   16, 2, False],\n",
    "                  [16,  32, 2, False],\n",
    "                  [32,  64, 2, False],\n",
    "                  [64,  64, 2, False]],\n",
    "            \n",
    "            'C': [[3,   8,  2, False],\n",
    "                  [8,   16, 2, False],\n",
    "                  [16,  32, 2, True],\n",
    "                  [32,  64, 2, True],\n",
    "                  [64,  64, 2, True]],\n",
    "            \n",
    "            'D': [[3,   8,  2, False],\n",
    "                  [8,   16, 2, False],\n",
    "                  [16,  32, 3, False],\n",
    "                  [32,  64, 3, False],\n",
    "                  [64,  64, 3, False]],\n",
    "            \n",
    "            'E': [[3,   8,  2, False],\n",
    "                  [8,   16, 2, False],\n",
    "                  [16,  32, 4, False],\n",
    "                  [32,  64, 4, False],\n",
    "                  [64,  64, 4, False]]\n",
    "        }\n",
    "        self.configuration = configuration\n",
    "        self.batch_norm = batch_norm\n",
    "        self.blocks = []\n",
    "        for arg_list in self.configurations[self.configuration]:\n",
    "            self.blocks.append(VGG_block(*arg_list, self.batch_norm))\n",
    "        self.blocks = nn.Sequential(*self.blocks)\n",
    "        \n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Conv2d(64, 512, kernel_size=2),\n",
    "            nn.Dropout2d(p=dropout, inplace=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.Dropout2d(p=dropout, inplace=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 10, kernel_size=1),\n",
    "            # 把后两个空间维度合并成一个\n",
    "            nn.Flatten(start_dim=2, end_dim=-1)\n",
    "        )\n",
    "\n",
    "    def print_num_params(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f'{total_params:,} total parameters.')\n",
    "        total_trainable_params = sum(\n",
    "            p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f'{total_trainable_params:,} trainable parameters.')\n",
    "        \n",
    "    def forward(self, X):\n",
    "        output = self.blocks(X)\n",
    "        output = self.FC(output)\n",
    "        # 这里为了实现简单，把空间平均的操作放在softmax前面了\n",
    "        # 输出维度为 (`batch_size`, 10)\n",
    "        return output.mean(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b442c89c-17ec-45b2-9c39-63419f2dfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_scale_eval_SQ(S):\n",
    "    if isinstance(S, int):\n",
    "        Q = S\n",
    "    elif isinstance(S, list):\n",
    "        assert(len(S) == 2)\n",
    "        Q = int(0.5*(S[0] + S[1]))\n",
    "    return S, Q\n",
    "\n",
    "def multi_scale_eval_SQ(S):\n",
    "    if isinstance(S, int):\n",
    "        Q = [S-8, S, S+8]\n",
    "    elif isinstance(S, list):\n",
    "        assert(len(S) == 2)\n",
    "        Q = [S[0], int(0.5*(S[0] + S[1])), S[1]]\n",
    "    return S, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a93a60-0a99-4fef-9795-98aa162e76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_S_and_Q(S, single_scale_eval):\n",
    "    if single_scale_eval:\n",
    "        return single_scale_eval_SQ(S)\n",
    "    else:\n",
    "        return multi_scale_eval_SQ(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f2c21ea-7af0-439b-9857-eab6db51cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluater:\n",
    "    def __init__(self, S, batch_size, mode='single'):\n",
    "        self.single_scale = mode=='single'\n",
    "        self.S, self.Q = get_S_and_Q(S, self.single_scale)\n",
    "        if self.single_scale:\n",
    "            self.datasets = [TestDataset(self.Q, False), TestDataset(self.Q, True)]\n",
    "        else:\n",
    "            self.datasets = []\n",
    "            for q in self.Q:\n",
    "                self.datasets += [TestDataset(q, False), TestDataset(q, True)]\n",
    "        self.dataloaders = [data.DataLoader(dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=8) for dataset in self.datasets]\n",
    "    def evaluate(self, net, criterion):\n",
    "        net.eval()\n",
    "        loss, accuracy = [], []\n",
    "        outputs = {}\n",
    "        with torch.no_grad():\n",
    "            for dataloader in self.dataloaders:\n",
    "                for i, (input, _) in enumerate(dataloader):\n",
    "                    input = input.to(device)\n",
    "                    output = net(input)\n",
    "                    try:\n",
    "                        outputs[i] += F.softmax(output, dim=1)\n",
    "                    except KeyError:\n",
    "                        outputs[i] = F.softmax(output, dim=1)\n",
    "            for i, (_, target) in enumerate(self.dataloaders[0]):\n",
    "                target = target.to(device)\n",
    "                loss.append(criterion(outputs[i] / len(self.datasets), target))\n",
    "                accuracy.append((outputs[i].argmax(dim=1)==target).sum() / target.shape[0])\n",
    "        loss = torch.tensor(loss).mean().item()\n",
    "        accuracy = torch.tensor(accuracy).mean().item()\n",
    "        return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c1e35f-5a9c-4a87-83e6-52d600ea556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    return (optimizer.state_dict()['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd7d25b-fd3f-49c9-aac9-c60813245a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VGG(net,\n",
    "              batch_size,\n",
    "              num_epochs,\n",
    "              lr,\n",
    "              evaluater,\n",
    "              S=[64, 128],\n",
    "              weight_decay=5e-4):\n",
    "\n",
    "    writer = SummaryWriter(f'runs/VGG-mini-{net.configuration}'+'-batchnorm' if net.batch_norm else '')\n",
    "    cifar_train = TrainDataset(S)\n",
    "    train_iter = data.DataLoader(cifar_train, batch_size=batch_size,\n",
    "                                 shuffle=True, num_workers=8)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "    net.apply(init_weights)\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                           factor=0.1,\n",
    "                                                           patience=3,\n",
    "                                                           threshold=1e-3,\n",
    "                                                           verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        tic = time.time()\n",
    "        # 训练损失之和，训练准确率之和，范例数\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (input, target) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            input, target = input.to(device), target.to(device)\n",
    "            output = net(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(loss * input.shape[0],\n",
    "                           d2l.accuracy(output, target),\n",
    "                           input.shape[0])\n",
    "            timer.stop()\n",
    "            train_loss = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            \n",
    "            # if (i+1) % (num_batches//20) == 0:\n",
    "            #     print(f\"loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "        valid_loss, valid_acc = evaluater.evaluate(net, criterion)\n",
    "        writer.add_scalar('train/loss', train_loss, global_step=epoch+1)\n",
    "        writer.add_scalar('train/accuracy', train_acc, global_step=epoch+1)\n",
    "        writer.add_scalar('valid/loss', valid_loss, global_step=epoch+1)\n",
    "        writer.add_scalar('valid/accuracy', valid_acc, global_step=epoch+1)\n",
    "        writer.add_scalar('learning rate', get_lr(optimizer), global_step=epoch+1)\n",
    "        scheduler.step(valid_loss)\n",
    "        toc = time.time()\n",
    "        print(f\"epoch {epoch+1:2d}, train loss: {train_loss:.4f}, train accuracy: {train_acc:.4f}, \\\n",
    "valid loss: {valid_loss:.4f}, valid accuracy: {valid_acc:.4f}, time: {toc-tic:.4f}\")\n",
    "    valid_loss, valid_acc = evaluater.evaluate(net, criterion)\n",
    "    print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'valid loss {valid_loss:.3f}, valid acc {valid_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c3985d5-9f22-4d65-aa40-97e7c38ae9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544,618 total parameters.\n",
      "544,618 trainable parameters.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG_mini(\n",
       "  (blocks): Sequential(\n",
       "    (0): VGG_block(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): VGG_block(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): VGG_block(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): VGG_block(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): VGG_block(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (FC): Sequential(\n",
       "    (0): Conv2d(64, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (1): Dropout2d(p=0.5, inplace=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): Dropout2d(p=0.5, inplace=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): Flatten(start_dim=2, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = VGG_mini(configuration='A',\n",
    "               batch_norm=True,\n",
    "               dropout=0.5).to(device)\n",
    "net.print_num_params()\n",
    "S = [64, 128]\n",
    "mode = 'multi'\n",
    "evaluater = Evaluater(S, mode=mode, batch_size=256)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512f6226-c6d3-481c-be69-03a63a735622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.302577495574951, 0.10205078125)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluater.evaluate(net, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b518b37b-081b-47f0-92f5-112d3d34ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch  1, train loss: 2.6515, train accuracy: 0.1854, valid loss: 2.2295, valid accuracy: 0.2988, time: 12.5906\n",
      "epoch  2, train loss: 1.9511, train accuracy: 0.2614, valid loss: 2.1940, valid accuracy: 0.3642, time: 13.1923\n",
      "epoch  3, train loss: 1.8434, train accuracy: 0.3063, valid loss: 2.1711, valid accuracy: 0.4008, time: 12.8884\n",
      "epoch  4, train loss: 1.7576, train accuracy: 0.3432, valid loss: 2.1673, valid accuracy: 0.4279, time: 12.5945\n",
      "epoch  5, train loss: 1.6900, train accuracy: 0.3739, valid loss: 2.1620, valid accuracy: 0.4605, time: 12.5882\n",
      "epoch  6, train loss: 1.6283, train accuracy: 0.3983, valid loss: 2.1356, valid accuracy: 0.4918, time: 12.5929\n",
      "epoch  7, train loss: 1.5745, train accuracy: 0.4230, valid loss: 2.1312, valid accuracy: 0.4603, time: 12.5385\n",
      "epoch  8, train loss: 1.5124, train accuracy: 0.4536, valid loss: 2.1052, valid accuracy: 0.4648, time: 12.6961\n",
      "epoch  9, train loss: 1.4602, train accuracy: 0.4735, valid loss: 2.1041, valid accuracy: 0.5202, time: 12.6184\n",
      "epoch 10, train loss: 1.4076, train accuracy: 0.4976, valid loss: 2.0677, valid accuracy: 0.5293, time: 12.7075\n",
      "epoch 11, train loss: 1.3580, train accuracy: 0.5161, valid loss: 2.0623, valid accuracy: 0.5938, time: 12.7053\n",
      "epoch 12, train loss: 1.3053, train accuracy: 0.5395, valid loss: 2.0211, valid accuracy: 0.6215, time: 12.5434\n",
      "epoch 13, train loss: 1.2631, train accuracy: 0.5552, valid loss: 2.0256, valid accuracy: 0.5974, time: 12.6266\n",
      "epoch 14, train loss: 1.2220, train accuracy: 0.5709, valid loss: 2.0085, valid accuracy: 0.6388, time: 12.5455\n",
      "epoch 15, train loss: 1.1884, train accuracy: 0.5827, valid loss: 1.9706, valid accuracy: 0.6766, time: 12.9053\n",
      "epoch 16, train loss: 1.1562, train accuracy: 0.5946, valid loss: 1.9820, valid accuracy: 0.6160, time: 12.7851\n",
      "epoch 17, train loss: 1.1178, train accuracy: 0.6089, valid loss: 1.9367, valid accuracy: 0.6991, time: 12.5058\n",
      "epoch 18, train loss: 1.0953, train accuracy: 0.6195, valid loss: 1.9341, valid accuracy: 0.6958, time: 12.6570\n",
      "epoch 19, train loss: 1.0745, train accuracy: 0.6314, valid loss: 1.9203, valid accuracy: 0.7146, time: 12.4882\n",
      "epoch 20, train loss: 1.0367, train accuracy: 0.6401, valid loss: 1.9218, valid accuracy: 0.7056, time: 12.6848\n",
      "epoch 21, train loss: 1.0169, train accuracy: 0.6484, valid loss: 1.9159, valid accuracy: 0.6889, time: 12.5684\n",
      "epoch 22, train loss: 0.9973, train accuracy: 0.6547, valid loss: 1.8887, valid accuracy: 0.7409, time: 12.4989\n",
      "epoch 23, train loss: 0.9812, train accuracy: 0.6634, valid loss: 1.8611, valid accuracy: 0.7707, time: 12.7805\n",
      "epoch 24, train loss: 0.9620, train accuracy: 0.6710, valid loss: 1.8549, valid accuracy: 0.7567, time: 12.6100\n",
      "epoch 25, train loss: 0.9442, train accuracy: 0.6766, valid loss: 1.8454, valid accuracy: 0.7665, time: 12.7027\n",
      "epoch 26, train loss: 0.9373, train accuracy: 0.6784, valid loss: 1.8636, valid accuracy: 0.7420, time: 12.7363\n",
      "epoch 27, train loss: 0.9188, train accuracy: 0.6887, valid loss: 1.8727, valid accuracy: 0.7357, time: 12.6516\n",
      "epoch 28, train loss: 0.9035, train accuracy: 0.6919, valid loss: 1.8661, valid accuracy: 0.7448, time: 12.8971\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "epoch 29, train loss: 0.8900, train accuracy: 0.6936, valid loss: 1.8466, valid accuracy: 0.7588, time: 12.5980\n",
      "epoch 30, train loss: 0.8240, train accuracy: 0.7165, valid loss: 1.7998, valid accuracy: 0.8095, time: 12.4537\n",
      "epoch 31, train loss: 0.7888, train accuracy: 0.7306, valid loss: 1.7910, valid accuracy: 0.8138, time: 12.5100\n",
      "epoch 32, train loss: 0.7816, train accuracy: 0.7339, valid loss: 1.7829, valid accuracy: 0.8216, time: 12.9236\n",
      "epoch 33, train loss: 0.7803, train accuracy: 0.7313, valid loss: 1.7871, valid accuracy: 0.8238, time: 12.9492\n",
      "epoch 34, train loss: 0.7686, train accuracy: 0.7355, valid loss: 1.7828, valid accuracy: 0.8243, time: 13.4415\n",
      "epoch 35, train loss: 0.7708, train accuracy: 0.7372, valid loss: 1.7850, valid accuracy: 0.8188, time: 12.9322\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 36, train loss: 0.7699, train accuracy: 0.7378, valid loss: 1.7860, valid accuracy: 0.8225, time: 12.7873\n",
      "epoch 37, train loss: 0.7555, train accuracy: 0.7403, valid loss: 1.7831, valid accuracy: 0.8215, time: 12.9614\n",
      "epoch 38, train loss: 0.7506, train accuracy: 0.7407, valid loss: 1.7805, valid accuracy: 0.8237, time: 13.5233\n",
      "epoch 39, train loss: 0.7534, train accuracy: 0.7418, valid loss: 1.7818, valid accuracy: 0.8217, time: 13.0596\n",
      "epoch 40, train loss: 0.7502, train accuracy: 0.7439, valid loss: 1.7799, valid accuracy: 0.8234, time: 12.7334\n",
      "epoch 41, train loss: 0.7486, train accuracy: 0.7422, valid loss: 1.7809, valid accuracy: 0.8226, time: 12.6343\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 42, train loss: 0.7455, train accuracy: 0.7462, valid loss: 1.7789, valid accuracy: 0.8228, time: 12.8582\n",
      "epoch 43, train loss: 0.7574, train accuracy: 0.7413, valid loss: 1.7786, valid accuracy: 0.8231, time: 13.1694\n",
      "epoch 44, train loss: 0.7510, train accuracy: 0.7439, valid loss: 1.7793, valid accuracy: 0.8223, time: 12.8260\n",
      "epoch 45, train loss: 0.7528, train accuracy: 0.7441, valid loss: 1.7791, valid accuracy: 0.8237, time: 13.1747\n",
      "epoch 46, train loss: 0.7459, train accuracy: 0.7453, valid loss: 1.7793, valid accuracy: 0.8225, time: 13.3251\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-07.\n",
      "epoch 47, train loss: 0.7470, train accuracy: 0.7438, valid loss: 1.7798, valid accuracy: 0.8213, time: 12.7277\n",
      "epoch 48, train loss: 0.7508, train accuracy: 0.7430, valid loss: 1.7798, valid accuracy: 0.8242, time: 13.2076\n",
      "epoch 49, train loss: 0.7531, train accuracy: 0.7420, valid loss: 1.7786, valid accuracy: 0.8245, time: 13.1571\n",
      "epoch 50, train loss: 0.7476, train accuracy: 0.7453, valid loss: 1.7767, valid accuracy: 0.8256, time: 13.3788\n",
      "epoch 51, train loss: 0.7505, train accuracy: 0.7430, valid loss: 1.7793, valid accuracy: 0.8244, time: 14.1401\n",
      "epoch 52, train loss: 0.7508, train accuracy: 0.7427, valid loss: 1.7791, valid accuracy: 0.8224, time: 12.9027\n",
      "epoch 53, train loss: 0.7484, train accuracy: 0.7449, valid loss: 1.7773, valid accuracy: 0.8252, time: 13.2434\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-08.\n",
      "epoch 54, train loss: 0.7435, train accuracy: 0.7444, valid loss: 1.7791, valid accuracy: 0.8242, time: 12.7736\n",
      "epoch 55, train loss: 0.7465, train accuracy: 0.7449, valid loss: 1.7792, valid accuracy: 0.8243, time: 13.2858\n",
      "epoch 56, train loss: 0.7492, train accuracy: 0.7428, valid loss: 1.7769, valid accuracy: 0.8252, time: 12.9404\n",
      "epoch 57, train loss: 0.7476, train accuracy: 0.7434, valid loss: 1.7763, valid accuracy: 0.8249, time: 13.8211\n",
      "epoch 58, train loss: 0.7538, train accuracy: 0.7423, valid loss: 1.7785, valid accuracy: 0.8237, time: 13.9595\n",
      "epoch 59, train loss: 0.7525, train accuracy: 0.7420, valid loss: 1.7778, valid accuracy: 0.8263, time: 13.7469\n",
      "epoch 60, train loss: 0.7523, train accuracy: 0.7450, valid loss: 1.7799, valid accuracy: 0.8239, time: 13.7541\n",
      "epoch 61, train loss: 0.7477, train accuracy: 0.7454, valid loss: 1.7785, valid accuracy: 0.8243, time: 13.5063\n",
      "epoch 62, train loss: 0.7542, train accuracy: 0.7424, valid loss: 1.7770, valid accuracy: 0.8243, time: 13.1467\n",
      "epoch 63, train loss: 0.7508, train accuracy: 0.7411, valid loss: 1.7768, valid accuracy: 0.8255, time: 13.8247\n",
      "epoch 64, train loss: 0.7425, train accuracy: 0.7444, valid loss: 1.7793, valid accuracy: 0.8235, time: 13.8894\n",
      "epoch 65, train loss: 0.7495, train accuracy: 0.7437, valid loss: 1.7785, valid accuracy: 0.8265, time: 13.6544\n",
      "epoch 66, train loss: 0.7442, train accuracy: 0.7445, valid loss: 1.7779, valid accuracy: 0.8246, time: 13.2956\n",
      "epoch 67, train loss: 0.7506, train accuracy: 0.7425, valid loss: 1.7790, valid accuracy: 0.8240, time: 12.8427\n",
      "epoch 68, train loss: 0.7449, train accuracy: 0.7437, valid loss: 1.7797, valid accuracy: 0.8250, time: 12.7695\n",
      "epoch 69, train loss: 0.7459, train accuracy: 0.7448, valid loss: 1.7780, valid accuracy: 0.8274, time: 13.3993\n",
      "epoch 70, train loss: 0.7503, train accuracy: 0.7440, valid loss: 1.7783, valid accuracy: 0.8248, time: 13.2400\n",
      "train loss 0.750, train acc 0.744, valid loss 1.778, valid acc 0.825\n",
      "17769.5 examples/sec on cuda\n"
     ]
    }
   ],
   "source": [
    "train_VGG(net,\n",
    "          batch_size=256,\n",
    "          num_epochs=70,\n",
    "          lr=1e-3,\n",
    "          evaluater=evaluater,\n",
    "          S=[64, 128],\n",
    "          weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff4de949-60f9-41f2-af06-4cc0879a0abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.778253197669983, 0.8248046636581421)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluater.evaluate(net, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47073b8f-777c-4293-bdd9-0f06b3ddcbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, f'VGG-mini-{net.configuration}' + '-batchnorm.pth' if net.batch_norm else '.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
