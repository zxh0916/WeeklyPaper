{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907af153-e784-4273-8976-4d19a1ffed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from modules import *\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f134a3-d312-4b0c-8683-2d1b5dc3973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 百度来的，不然下载不动。。\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db290cc7-61cd-4b05-b2fa-f4c7aa1a340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "cifar_train = torchvision.datasets.CIFAR10(root=\"../data\", train=True, download=True)\n",
    "print(cifar_train.data.shape) # (50000, 32, 32, 3)\n",
    "cifardata = cifar_train.data / 255\n",
    "mean_pic = torch.tensor(cifardata.mean(axis=(0))).permute(2, 0, 1)\n",
    "print(mean_pic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1216eb7e-6192-4c4b-86e3-558f1190b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_and_valid = data.random_split(torchvision.datasets.CIFAR10(root=\"../data\", train=True, download=True),\n",
    "                                    [45000, 5000],\n",
    "                                    generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c68bc9-cd3e-4a40-814b-92015749ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, dataset, aug=True):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        if aug:\n",
    "            self.trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                             transforms.Lambda(lambda pic: pic-mean_pic.to(pic.device)),\n",
    "                                             transforms.RandomCrop(32, padding=4),\n",
    "                                             transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                             transforms.ConvertImageDtype(torch.float)])\n",
    "        else:\n",
    "            self.trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                             transforms.Lambda(lambda pic: pic-mean_pic.to(pic.device)),\n",
    "                                             transforms.ConvertImageDtype(torch.float)])\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.trans(self.dataset[index][0]),\n",
    "                self.dataset[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7231c0d2-424b-4f97-a511-ec37e42479c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                         transforms.Lambda(lambda pic: pic-mean_pic.to(pic.device)),\n",
    "                                         transforms.ConvertImageDtype(torch.float)])\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.trans(self.dataset[index][0]),\n",
    "                self.dataset[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15dc5f86-2cff-4fa7-a7ae-02cd37c4b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrainDataset(train_and_valid[0], aug=True)\n",
    "valid_dataset = TestDataset(train_and_valid[1])\n",
    "test_dataset = TestDataset(torchvision.datasets.CIFAR10(root=\"../data\", train=False, download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ded660-069e-46bd-a40b-c4d4cd56f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss_acc(net, data_iter, criterion, device=device):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度。\"\"\"\n",
    "    net.eval()  # 设置为评估模式\n",
    "    loss = []\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for input, target in data_iter:\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = net(input)\n",
    "            loss.append(float(criterion(output, target).item()))\n",
    "            metric.add(d2l.accuracy(output, target), target.numel())\n",
    "    return sum(loss) / len(loss), metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3eabee0-99d4-4219-adbc-2170093a9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    return (optimizer.state_dict()['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798b5ec2-a5cb-4201-be26-a1c0b2a4c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DenseNet(net,\n",
    "                   batch_size,\n",
    "                   lr,\n",
    "                   num_epochs,\n",
    "                   weight_decay=1e-4):\n",
    "\n",
    "    train_iter = data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                 shuffle=True, num_workers=8)\n",
    "    valid_iter = data.DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                                 shuffle=False, num_workers=8)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "    net.apply(init_weights)\n",
    "    optimizer = torch.optim.SGD(net.parameters(),\n",
    "                                lr=lr,\n",
    "                                weight_decay=weight_decay,\n",
    "                                momentum=0.9)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, verbose=True)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, threshold=0.001, verbose=True)\n",
    "    scheduler_name = str(scheduler.__class__).split('.')[-1][:-2]\n",
    "    writer = SummaryWriter(f'runs/DenseNet_CIFAR_L={net.L}_k={net.k}_theta={net.theta}')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        tic = time.time()\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (input, target) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            input, target = input.to(device), target.to(device)\n",
    "            output = net(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(loss * input.shape[0],\n",
    "                           d2l.accuracy(output, target),\n",
    "                           input.shape[0])\n",
    "            timer.stop()\n",
    "            train_loss = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "        valid_loss, valid_acc = evaluate_loss_acc(net, valid_iter, criterion, device)\n",
    "        writer.add_scalar('train/loss', train_loss, global_step=epoch+1)\n",
    "        writer.add_scalar('train/accuracy', train_acc, global_step=epoch+1)\n",
    "        writer.add_scalar('valid/loss', valid_loss, global_step=epoch+1)\n",
    "        writer.add_scalar('valid/accuracy', valid_acc, global_step=epoch+1)\n",
    "        writer.add_scalar('learning rate', get_lr(optimizer), global_step=epoch+1)\n",
    "        # scheduler.step()\n",
    "        scheduler.step(valid_loss)\n",
    "        toc = time.time()\n",
    "        print(f\"epoch {epoch+1:3d}, train loss: {train_loss:.4f}, train accuracy: {train_acc:.4f}, \\\n",
    "valid loss: {valid_loss:.4f}, valid accuracy: {valid_acc:.4f}, time: {toc-tic:.4f}\")\n",
    "    print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'valid loss {valid_loss:.3f}, valid acc {valid_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51811b46-0033-4ced-aa29-aa09e0fb59bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486,436 total parameters.\n",
      "486,436 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "net = DenseNet(L=40, k=12, theta=0.5, block=Bottleneck, num_classes=10).to(device)\n",
    "net.print_num_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3262ae6c-ae12-490f-8c3b-22c69d9aa76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1, train loss: 1.6552, train accuracy: 0.3928, valid loss: 1.6033, valid accuracy: 0.4588, time: 52.6598\n",
      "epoch   2, train loss: 1.1895, train accuracy: 0.5782, valid loss: 0.9570, valid accuracy: 0.6662, time: 51.3201\n",
      "epoch   3, train loss: 0.9363, train accuracy: 0.6723, valid loss: 1.2877, valid accuracy: 0.5914, time: 52.8655\n",
      "epoch   4, train loss: 0.7862, train accuracy: 0.7285, valid loss: 1.0148, valid accuracy: 0.6826, time: 52.0783\n",
      "epoch   5, train loss: 0.6905, train accuracy: 0.7637, valid loss: 0.7683, valid accuracy: 0.7448, time: 50.9403\n",
      "epoch   6, train loss: 0.6227, train accuracy: 0.7874, valid loss: 0.6483, valid accuracy: 0.7812, time: 50.7741\n",
      "epoch   7, train loss: 0.5717, train accuracy: 0.8045, valid loss: 0.6400, valid accuracy: 0.7810, time: 51.9899\n",
      "epoch   8, train loss: 0.5434, train accuracy: 0.8151, valid loss: 0.7675, valid accuracy: 0.7536, time: 51.9333\n",
      "epoch   9, train loss: 0.5217, train accuracy: 0.8226, valid loss: 0.6384, valid accuracy: 0.7898, time: 53.0679\n",
      "epoch  10, train loss: 0.4938, train accuracy: 0.8333, valid loss: 0.5006, valid accuracy: 0.8338, time: 52.9262\n",
      "epoch  11, train loss: 0.4728, train accuracy: 0.8380, valid loss: 0.8360, valid accuracy: 0.7654, time: 52.4712\n",
      "epoch  12, train loss: 0.4650, train accuracy: 0.8426, valid loss: 0.5836, valid accuracy: 0.8130, time: 52.6872\n",
      "epoch  13, train loss: 0.4466, train accuracy: 0.8475, valid loss: 0.6014, valid accuracy: 0.8002, time: 52.9021\n",
      "epoch  14, train loss: 0.4419, train accuracy: 0.8484, valid loss: 0.5821, valid accuracy: 0.8152, time: 52.6821\n",
      "epoch  15, train loss: 0.4210, train accuracy: 0.8555, valid loss: 0.4435, valid accuracy: 0.8488, time: 52.6891\n",
      "epoch  16, train loss: 0.4187, train accuracy: 0.8561, valid loss: 0.4870, valid accuracy: 0.8442, time: 50.6730\n",
      "epoch  17, train loss: 0.4117, train accuracy: 0.8599, valid loss: 0.5188, valid accuracy: 0.8304, time: 49.9896\n",
      "epoch  18, train loss: 0.4039, train accuracy: 0.8614, valid loss: 0.5137, valid accuracy: 0.8408, time: 49.9069\n",
      "epoch  19, train loss: 0.4012, train accuracy: 0.8618, valid loss: 0.4306, valid accuracy: 0.8574, time: 49.9398\n",
      "epoch  20, train loss: 0.3949, train accuracy: 0.8648, valid loss: 0.5695, valid accuracy: 0.8104, time: 49.9698\n",
      "epoch  21, train loss: 0.3876, train accuracy: 0.8662, valid loss: 0.4382, valid accuracy: 0.8620, time: 50.0206\n",
      "epoch  22, train loss: 0.3767, train accuracy: 0.8706, valid loss: 0.7479, valid accuracy: 0.7760, time: 49.9857\n",
      "epoch  23, train loss: 0.3765, train accuracy: 0.8706, valid loss: 0.4112, valid accuracy: 0.8598, time: 49.9611\n",
      "epoch  24, train loss: 0.3696, train accuracy: 0.8722, valid loss: 0.6162, valid accuracy: 0.8122, time: 49.8835\n",
      "epoch  25, train loss: 0.3741, train accuracy: 0.8711, valid loss: 0.5105, valid accuracy: 0.8446, time: 49.9616\n",
      "epoch  26, train loss: 0.3602, train accuracy: 0.8758, valid loss: 0.7359, valid accuracy: 0.7922, time: 49.9864\n",
      "epoch  27, train loss: 0.3483, train accuracy: 0.8794, valid loss: 0.5481, valid accuracy: 0.8296, time: 51.5494\n",
      "epoch  28, train loss: 0.3590, train accuracy: 0.8777, valid loss: 0.4152, valid accuracy: 0.8558, time: 50.4714\n",
      "epoch  29, train loss: 0.3491, train accuracy: 0.8797, valid loss: 0.4662, valid accuracy: 0.8524, time: 50.4198\n",
      "epoch  30, train loss: 0.3421, train accuracy: 0.8827, valid loss: 0.5200, valid accuracy: 0.8300, time: 50.4221\n",
      "epoch  31, train loss: 0.3435, train accuracy: 0.8815, valid loss: 0.5266, valid accuracy: 0.8348, time: 51.3324\n",
      "epoch  32, train loss: 0.3360, train accuracy: 0.8844, valid loss: 0.4628, valid accuracy: 0.8416, time: 50.4040\n",
      "epoch  33, train loss: 0.3399, train accuracy: 0.8820, valid loss: 0.3512, valid accuracy: 0.8792, time: 50.5290\n",
      "epoch  34, train loss: 0.3332, train accuracy: 0.8853, valid loss: 0.3716, valid accuracy: 0.8766, time: 50.4417\n",
      "epoch  35, train loss: 0.3275, train accuracy: 0.8869, valid loss: 0.5215, valid accuracy: 0.8360, time: 50.3610\n",
      "epoch  36, train loss: 0.3248, train accuracy: 0.8878, valid loss: 0.4394, valid accuracy: 0.8622, time: 50.7372\n",
      "epoch  37, train loss: 0.3171, train accuracy: 0.8908, valid loss: 0.4729, valid accuracy: 0.8488, time: 50.4790\n",
      "epoch  38, train loss: 0.3282, train accuracy: 0.8878, valid loss: 0.6806, valid accuracy: 0.8078, time: 50.4990\n",
      "epoch  39, train loss: 0.3173, train accuracy: 0.8894, valid loss: 0.3972, valid accuracy: 0.8734, time: 51.9931\n",
      "epoch  40, train loss: 0.3227, train accuracy: 0.8896, valid loss: 0.5135, valid accuracy: 0.8300, time: 52.5963\n",
      "epoch  41, train loss: 0.3154, train accuracy: 0.8903, valid loss: 0.3976, valid accuracy: 0.8684, time: 52.7832\n",
      "epoch  42, train loss: 0.3168, train accuracy: 0.8899, valid loss: 0.4046, valid accuracy: 0.8684, time: 52.3711\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6337/1039183322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_DenseNet(net,\n\u001b[0m\u001b[1;32m      2\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                weight_decay=1e-4)\n",
      "\u001b[0;32m/tmp/ipykernel_6337/2936384102.py\u001b[0m in \u001b[0;36mtrain_DenseNet\u001b[0;34m(net, batch_size, lr, num_epochs, weight_decay)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_DenseNet(net,\n",
    "               batch_size=64,\n",
    "               lr=0.1,\n",
    "               num_epochs=50,\n",
    "               weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b5980-f17e-4656-8e00-5e05004d53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "test_loss, test_acc = evaluate_loss_acc(net, test_iter, nn.CrossEntropyLoss())\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db75368-fa62-4934-880a-981311b344d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), f'DenseNet_CIFAR_L={net.L}_k={net.k}_theta={net.theta}_acc={test_acc}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
